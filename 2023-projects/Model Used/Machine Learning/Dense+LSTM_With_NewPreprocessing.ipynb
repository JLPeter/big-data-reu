{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLBbMrjmpDOK"
      },
      "source": [
        "# New Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xqe9ZBBXKttI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0a17586-36ce-40ff-cb89-7ca430e0edd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7MXnaEwpGe5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46482694-bc10-43d5-adc0-44a1d2f7f382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting imports\n",
            "Starting timer.\n",
            "Imports Complete\n"
          ]
        }
      ],
      "source": [
        "#imports\n",
        "print(\"Starting imports\")\n",
        "#basics\n",
        "import time\n",
        "print(\"Starting timer.\")\n",
        "startTime = time.time()\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#cleaning\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "print(\"Imports Complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmwL5liG52EI"
      },
      "source": [
        "## Get Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6tHhIxwpGnu"
      },
      "outputs": [],
      "source": [
        "#paths\n",
        "mainPath = '/content/drive/MyDrive/REU 2023 Team 1: Ice Bed Topography Prediction/Research/Lu_Folder/Data_derivedVelocity/Data_derivedVelocity/'\n",
        "data_full_ = mainPath + 'data_full_vMag.csv'\n",
        "data_1201_ = mainPath + 'd1201_vMag.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSd5zR4isB45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2174de1e-2fa8-4231-8871-0c29780bee21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItKd5FYdum2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0297b525-a460-4e68-d6a6-e6dd660a3865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading Data In_\n",
            "Data read in completed.\n"
          ]
        }
      ],
      "source": [
        "#read data in\n",
        "print(\"Reading Data In_\")\n",
        "df_all = pd.read_csv(data_full_)\n",
        "\n",
        "df1201 = pd.read_csv(data_1201_)\n",
        "print(\"Data read in completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2Ox7DBL55V_"
      },
      "source": [
        "## Create functions from Homayra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWR-_GS1ZUKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fbb0ef7-b062-4dc9-aac9-dc21a72b66b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Establishing RMSPE functions.\n"
          ]
        }
      ],
      "source": [
        "print(\"Establishing RMSPE functions.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G73ihBVVpGjN"
      },
      "outputs": [],
      "source": [
        "def rmspe(y_true, y_pred):\n",
        "    return np.sqrt(np.nanmean(np.square(((y_true - y_pred) / y_true))))*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWNov_aZpGlX"
      },
      "outputs": [],
      "source": [
        "def rmspe_1(y_true, y_pred):\n",
        "    return np.sqrt(np.nanmean(np.square(y_true - y_pred) / y_true))*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLAAj5qJZZp-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "217ebc4b-fedf-42c3-bfe7-fc8f5fbbf09d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function established.\n"
          ]
        }
      ],
      "source": [
        "print(\"Function established.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czPqgSZ25_Ps"
      },
      "source": [
        "## Clean Data/Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVF9u0eHx6Hf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a92adf3-6e1a-40a8-8232-310334c97093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Begin data cleaning.\n",
            "Data cleaned.\n",
            "Scaling beginning.\n",
            "Scaling Complete.\n",
            "Splitting Data Beginning.\n",
            "Data train-split complete with: 60.0% training, 40.0% testing, 20.0% validation\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"Begin data cleaning.\")\n",
        "\n",
        "df1201 = df1201.drop(columns=['Unnamed: 0.1'])\n",
        "df_all = df_all.drop(columns=['Unnamed: 0.1'])\n",
        "\n",
        "# 1201 drop location variables\n",
        "df1201_feats = df1201.drop(columns=['surf_x', 'surf_y'])\n",
        "\n",
        "# df_all drop location variables\n",
        "df_all_feats_target = df_all.drop(columns=['surf_x', 'surf_y', 'track_bed_x', 'track_bed_y'])\n",
        "\n",
        "# 1201 order to align with df_all\n",
        "df1201_feats_ordered = df1201_feats[['surf_vx', 'surf_vy', 'surf_elv', 'surf_dhdt', 'surf_SMB']]\n",
        "\n",
        "# set the feature variables to our independent characteristic variables\n",
        "feature_cols = ['surf_vx', 'surf_vy', 'surf_elv', 'surf_dhdt', 'surf_SMB', 'v_mag']\n",
        "\n",
        "# split into X and Y\n",
        "X_given = df_all_feats_target[feature_cols]\n",
        "Y_given = df_all_feats_target['track_bed_target']\n",
        "\n",
        "#FIX\n",
        "num_missing_cols = X_given.shape[1] - df1201_feats_ordered.shape[1]\n",
        "if num_missing_cols > 0:\n",
        "    missing_cols = np.zeros((df1201_feats_ordered.shape[0], num_missing_cols))\n",
        "    df1201_feats_ordered = np.concatenate((df1201_feats_ordered, missing_cols), axis=1)\n",
        "\n",
        "# Combine all known X and validation 1201 X for standardizing\n",
        "X_all = np.concatenate((X_given, df1201_feats_ordered))\n",
        "\n",
        "# make y into a dataframe to be standardized\n",
        "Y_all = pd.DataFrame(Y_given)\n",
        "\n",
        "print(\"Data cleaned.\\nScaling beginning.\")\n",
        "\n",
        "# standardize\n",
        "# Not setting feature range, let it be automatically determined\n",
        "scaler_X = StandardScaler()\n",
        "scaler_Y = StandardScaler()\n",
        "\n",
        "X_all_std = scaler_X.fit_transform(X_all)\n",
        "Y_all_std = scaler_Y.fit_transform(Y_all)\n",
        "\n",
        "# can alternatively use the MinMaxScaler\n",
        "print(\"Scaling Complete.\\nSplitting Data Beginning.\")\n",
        "\n",
        "# split of 1201 data from X_all_std\n",
        "X_non1201 = X_all_std[0:632706, :]\n",
        "X_1201_data = X_all_std[632706:, :]\n",
        "\n",
        "# # generate a randomseed for training and testing split\n",
        "# generated = np.random.randint(0, 1000, 1)[0]\n",
        "# print(f\"Generated random split for train-test: {generated}\")\n",
        "generated = 168\n",
        "\n",
        "# set the train-test split\n",
        "# 60-40 showed the most promising from previous research and additional testing\n",
        "train_size_ = 0.6\n",
        "# split training and test from df_all\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    X_non1201, Y_all_std, train_size=train_size_, test_size=1 - train_size_, random_state=generated\n",
        ")\n",
        "\n",
        "# get validation data\n",
        "val_split = 0.2  # can change as needed\n",
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    x_train, y_train, train_size=1 - val_split, test_size=val_split, random_state=generated\n",
        ")\n",
        "\n",
        "print(f\"Data train-split complete with: {train_size_ * 100}% training, {(1- train_size_) * 100}% testing, {val_split*100}% validation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmn7g_Dn6Fam"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "## Omar's model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QffnhPHbcyvL"
      },
      "outputs": [],
      "source": [
        "import keras,os\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten, Dropout, AveragePooling2D, LSTM, Activation, ConvLSTM2D, TimeDistributed, Input, Reshape\n",
        "from keras.layers import UpSampling1D, Conv2DTranspose, UpSampling2D, BatchNormalization\n",
        "from tensorflow.keras import callbacks\n",
        "import numpy as np\n",
        "\n",
        "def get_model(input_dims):\n",
        "    input_batch = Input(shape=input_dims)\n",
        "\n",
        "    conv_model = TimeDistributed(Dense(128, activation=\"sigmoid\"), name='ConvL1')(input_batch)\n",
        "    conv_model = TimeDistributed(BatchNormalization())(conv_model)\n",
        "    conv_model = TimeDistributed(Dense(128, activation=\"sigmoid\"), name='ConvL2' )(conv_model)\n",
        "    conv_model = TimeDistributed(BatchNormalization())(conv_model)\n",
        "    conv_model = TimeDistributed(Dropout(0.5))(conv_model)\n",
        "    conv_model = TimeDistributed(Dense(64, activation=\"sigmoid\"), name='ConvL3' )(conv_model)\n",
        "    conv_model = TimeDistributed(BatchNormalization())(conv_model)\n",
        "    conv_model = TimeDistributed(Dense(64, activation=\"sigmoid\"), name='ConvL4' )(conv_model)\n",
        "    conv_model = TimeDistributed(BatchNormalization())(conv_model)\n",
        "    conv_model = TimeDistributed(Dropout(0.5))(conv_model)\n",
        "    conv_model = TimeDistributed(Dense(32, activation=\"sigmoid\"), name='ConvL5' )(conv_model)\n",
        "    conv_model = TimeDistributed(BatchNormalization())(conv_model)\n",
        "    conv_model = TimeDistributed(Dense(32, activation=\"sigmoid\"), name='ConvL6' )(conv_model)\n",
        "    conv_model = TimeDistributed(BatchNormalization())(conv_model)\n",
        "    conv_model = TimeDistributed(Dropout(0.5))(conv_model)\n",
        "\n",
        "    lstm_network = LSTM(64, return_sequences=True)(conv_model)\n",
        "    lstm_network = LSTM(32, return_sequences=False)(lstm_network)\n",
        "    lstm_network = Dropout(0.5)(lstm_network)\n",
        "    lstm_network = Dense(32, activation='sigmoid', name='Dense1')(lstm_network)\n",
        "    lstm_network = Dense(1, activation='linear', name='Dense2')(lstm_network)\n",
        "\n",
        "    encoder = Model(inputs=input_batch, outputs=lstm_network, name='encoder')\n",
        "\n",
        "    return encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EVSetaIl7zV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9943cea-f07e-4db6-8437-4e59cb9b1fdf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303698, 1, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "data_train_X_lstm = x_train.reshape(x_train.shape[0], 1, x_train.shape[1])\n",
        "data_train_X_lstm.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xd-jpwLpl8SP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b93b1015-7f64-4c05-bcb6-a13ed14c7953"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(253083, 1, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "data_test_X_lstm = x_test.reshape(x_test.shape[0], 1, x_test.shape[1])\n",
        "data_test_X_lstm.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7Cq-WFWmAdE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1c39cd1-5019-45fd-ecc8-866965d22773"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1442401, 1, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "X_1201_data_lstm = X_1201_data.reshape(X_1201_data.shape[0], 1, X_1201_data.shape[1])\n",
        "X_1201_data_lstm.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjPRTK0HnIHj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4e50728-ebff-46c9-e6c7-41ae2476ae64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.60994894],\n",
              "       [ 1.27473612],\n",
              "       [ 1.03273313],\n",
              "       ...,\n",
              "       [-0.45522849],\n",
              "       [ 0.30980193],\n",
              "       [-0.096783  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9s9AuSHnLus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab7e2e3-26ba-4ad1-ccfe-b19e68f8583f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303698, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5avmYnKn-tz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee0d1aca-be76-42d3-962b-2ad5b716adf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1, 6)]            0         \n",
            "                                                                 \n",
            " ConvL1 (TimeDistributed)    (None, 1, 128)            896       \n",
            "                                                                 \n",
            " time_distributed_9 (TimeDis  (None, 1, 128)           512       \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " ConvL2 (TimeDistributed)    (None, 1, 128)            16512     \n",
            "                                                                 \n",
            " time_distributed_10 (TimeDi  (None, 1, 128)           512       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_11 (TimeDi  (None, 1, 128)           0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " ConvL3 (TimeDistributed)    (None, 1, 64)             8256      \n",
            "                                                                 \n",
            " time_distributed_12 (TimeDi  (None, 1, 64)            256       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " ConvL4 (TimeDistributed)    (None, 1, 64)             4160      \n",
            "                                                                 \n",
            " time_distributed_13 (TimeDi  (None, 1, 64)            256       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_14 (TimeDi  (None, 1, 64)            0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " ConvL5 (TimeDistributed)    (None, 1, 32)             2080      \n",
            "                                                                 \n",
            " time_distributed_15 (TimeDi  (None, 1, 32)            128       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " ConvL6 (TimeDistributed)    (None, 1, 32)             1056      \n",
            "                                                                 \n",
            " time_distributed_16 (TimeDi  (None, 1, 32)            128       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_17 (TimeDi  (None, 1, 32)            0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 1, 64)             24832     \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 32)                12416     \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " Dense1 (Dense)              (None, 32)                1056      \n",
            "                                                                 \n",
            " Dense2 (Dense)              (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 73,089\n",
            "Trainable params: 72,193\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "43/43 [==============================] - 30s 219ms/step - loss: 1.2680 - val_loss: 0.9925\n",
            "Epoch 2/200\n",
            "43/43 [==============================] - 6s 151ms/step - loss: 0.7046 - val_loss: 1.0017\n",
            "Epoch 3/200\n",
            "43/43 [==============================] - 8s 193ms/step - loss: 0.6209 - val_loss: 1.0502\n",
            "Epoch 4/200\n",
            "43/43 [==============================] - 7s 164ms/step - loss: 0.5727 - val_loss: 1.1763\n",
            "Epoch 5/200\n",
            "43/43 [==============================] - 8s 192ms/step - loss: 0.5386 - val_loss: 1.3489\n",
            "Epoch 6/200\n",
            "43/43 [==============================] - 7s 152ms/step - loss: 0.5221 - val_loss: 1.3949\n",
            "Epoch 7/200\n",
            "43/43 [==============================] - 9s 202ms/step - loss: 0.5077 - val_loss: 1.4127\n",
            "Epoch 8/200\n",
            "43/43 [==============================] - 6s 149ms/step - loss: 0.4960 - val_loss: 1.2975\n",
            "Epoch 9/200\n",
            "43/43 [==============================] - 9s 205ms/step - loss: 0.4860 - val_loss: 1.0813\n",
            "Epoch 10/200\n",
            "43/43 [==============================] - 7s 167ms/step - loss: 0.4807 - val_loss: 0.9119\n",
            "Epoch 11/200\n",
            "43/43 [==============================] - 9s 209ms/step - loss: 0.4736 - val_loss: 0.7850\n",
            "Epoch 12/200\n",
            "43/43 [==============================] - 7s 153ms/step - loss: 0.4699 - val_loss: 0.6789\n",
            "Epoch 13/200\n",
            "43/43 [==============================] - 8s 195ms/step - loss: 0.4656 - val_loss: 0.6098\n",
            "Epoch 14/200\n",
            "43/43 [==============================] - 7s 153ms/step - loss: 0.4586 - val_loss: 0.5061\n",
            "Epoch 15/200\n",
            "43/43 [==============================] - 8s 198ms/step - loss: 0.4545 - val_loss: 0.4644\n",
            "Epoch 16/200\n",
            "43/43 [==============================] - 6s 151ms/step - loss: 0.4502 - val_loss: 0.4237\n",
            "Epoch 17/200\n",
            "43/43 [==============================] - 8s 193ms/step - loss: 0.4473 - val_loss: 0.4314\n",
            "Epoch 18/200\n",
            "43/43 [==============================] - 6s 150ms/step - loss: 0.4433 - val_loss: 0.4174\n",
            "Epoch 19/200\n",
            "43/43 [==============================] - 8s 193ms/step - loss: 0.4399 - val_loss: 0.4118\n",
            "Epoch 20/200\n",
            "43/43 [==============================] - 6s 149ms/step - loss: 0.4369 - val_loss: 0.4054\n",
            "Epoch 21/200\n",
            "43/43 [==============================] - 8s 197ms/step - loss: 0.4354 - val_loss: 0.3977\n",
            "Epoch 22/200\n",
            "43/43 [==============================] - 6s 151ms/step - loss: 0.4310 - val_loss: 0.3919\n",
            "Epoch 23/200\n",
            "43/43 [==============================] - 8s 193ms/step - loss: 0.4302 - val_loss: 0.3917\n",
            "Epoch 24/200\n",
            "43/43 [==============================] - 7s 151ms/step - loss: 0.4256 - val_loss: 0.3836\n",
            "Epoch 25/200\n",
            "43/43 [==============================] - 8s 194ms/step - loss: 0.4240 - val_loss: 0.3859\n",
            "Epoch 26/200\n",
            "43/43 [==============================] - 6s 149ms/step - loss: 0.4211 - val_loss: 0.3745\n",
            "Epoch 27/200\n",
            "43/43 [==============================] - 8s 195ms/step - loss: 0.4199 - val_loss: 0.3893\n",
            "Epoch 28/200\n",
            "43/43 [==============================] - 7s 153ms/step - loss: 0.4176 - val_loss: 0.3810\n",
            "Epoch 29/200\n",
            "43/43 [==============================] - 8s 196ms/step - loss: 0.4129 - val_loss: 0.3740\n",
            "Epoch 30/200\n",
            "43/43 [==============================] - 7s 158ms/step - loss: 0.4121 - val_loss: 0.3804\n",
            "Epoch 31/200\n",
            "43/43 [==============================] - 9s 200ms/step - loss: 0.4094 - val_loss: 0.3665\n",
            "Epoch 32/200\n",
            "43/43 [==============================] - 7s 155ms/step - loss: 0.4086 - val_loss: 0.3677\n",
            "Epoch 33/200\n",
            "43/43 [==============================] - 9s 204ms/step - loss: 0.4038 - val_loss: 0.3640\n",
            "Epoch 34/200\n",
            "43/43 [==============================] - 7s 155ms/step - loss: 0.4017 - val_loss: 0.3650\n",
            "Epoch 35/200\n",
            "43/43 [==============================] - 9s 209ms/step - loss: 0.4007 - val_loss: 0.3630\n",
            "Epoch 36/200\n",
            "43/43 [==============================] - 7s 153ms/step - loss: 0.3989 - val_loss: 0.3724\n",
            "Epoch 37/200\n",
            "43/43 [==============================] - 8s 191ms/step - loss: 0.3969 - val_loss: 0.3633\n",
            "Epoch 38/200\n",
            "43/43 [==============================] - 6s 150ms/step - loss: 0.3935 - val_loss: 0.3581\n",
            "Epoch 39/200\n",
            "43/43 [==============================] - 8s 192ms/step - loss: 0.3910 - val_loss: 0.3480\n",
            "Epoch 40/200\n",
            "43/43 [==============================] - 6s 151ms/step - loss: 0.3896 - val_loss: 0.3492\n",
            "Epoch 41/200\n",
            "43/43 [==============================] - 8s 193ms/step - loss: 0.3855 - val_loss: 0.3419\n",
            "Epoch 42/200\n",
            "43/43 [==============================] - 6s 150ms/step - loss: 0.3842 - val_loss: 0.3459\n",
            "Epoch 43/200\n",
            "43/43 [==============================] - 8s 192ms/step - loss: 0.3829 - val_loss: 0.3508\n",
            "Epoch 44/200\n",
            "43/43 [==============================] - 6s 149ms/step - loss: 0.3814 - val_loss: 0.3442\n",
            "Epoch 45/200\n",
            "43/43 [==============================] - 8s 193ms/step - loss: 0.3780 - val_loss: 0.3426\n",
            "Epoch 46/200\n",
            "43/43 [==============================] - 7s 165ms/step - loss: 0.3789 - val_loss: 0.3482\n",
            "Epoch 47/200\n",
            "43/43 [==============================] - 8s 193ms/step - loss: 0.3766 - val_loss: 0.3356\n",
            "Epoch 48/200\n",
            "43/43 [==============================] - 7s 166ms/step - loss: 0.3743 - val_loss: 0.3423\n",
            "Epoch 49/200\n",
            "43/43 [==============================] - 8s 193ms/step - loss: 0.3721 - val_loss: 0.3400\n",
            "Epoch 50/200\n",
            "43/43 [==============================] - 6s 149ms/step - loss: 0.3706 - val_loss: 0.3304\n",
            "Epoch 51/200\n",
            "43/43 [==============================] - 8s 192ms/step - loss: 0.3685 - val_loss: 0.3346\n",
            "Epoch 52/200\n",
            "43/43 [==============================] - 7s 164ms/step - loss: 0.3671 - val_loss: 0.3323\n",
            "Epoch 53/200\n",
            "43/43 [==============================] - 8s 191ms/step - loss: 0.3651 - val_loss: 0.3266\n",
            "Epoch 54/200\n",
            "43/43 [==============================] - 6s 149ms/step - loss: 0.3641 - val_loss: 0.3228\n",
            "Epoch 55/200\n",
            "43/43 [==============================] - 8s 191ms/step - loss: 0.3620 - val_loss: 0.3168\n",
            "Epoch 56/200\n",
            "43/43 [==============================] - 6s 151ms/step - loss: 0.3633 - val_loss: 0.3234\n",
            "Epoch 57/200\n",
            "43/43 [==============================] - 8s 196ms/step - loss: 0.3607 - val_loss: 0.3103\n",
            "Epoch 58/200\n",
            "43/43 [==============================] - 6s 151ms/step - loss: 0.3584 - val_loss: 0.3221\n",
            "Epoch 59/200\n",
            "43/43 [==============================] - 8s 192ms/step - loss: 0.3567 - val_loss: 0.3285\n",
            "Epoch 60/200\n",
            "43/43 [==============================] - 6s 148ms/step - loss: 0.3564 - val_loss: 0.3166\n",
            "Epoch 61/200\n",
            "43/43 [==============================] - 8s 193ms/step - loss: 0.3545 - val_loss: 0.3112\n",
            "Epoch 62/200\n",
            "43/43 [==============================] - 6s 150ms/step - loss: 0.3553 - val_loss: 0.3127\n",
            "Epoch 63/200\n",
            "43/43 [==============================] - 8s 192ms/step - loss: 0.3506 - val_loss: 0.3012\n",
            "Epoch 64/200\n",
            "43/43 [==============================] - 7s 163ms/step - loss: 0.3518 - val_loss: 0.3052\n",
            "Epoch 65/200\n",
            "43/43 [==============================] - 8s 193ms/step - loss: 0.3509 - val_loss: 0.2950\n",
            "Epoch 66/200\n",
            "43/43 [==============================] - 6s 151ms/step - loss: 0.3493 - val_loss: 0.3029\n",
            "Epoch 67/200\n",
            "43/43 [==============================] - 8s 192ms/step - loss: 0.3450 - val_loss: 0.3051\n",
            "Epoch 68/200\n",
            "43/43 [==============================] - 6s 148ms/step - loss: 0.3477 - val_loss: 0.3081\n",
            "Epoch 69/200\n",
            "43/43 [==============================] - 9s 208ms/step - loss: 0.3444 - val_loss: 0.3021\n",
            "Epoch 70/200\n",
            "43/43 [==============================] - 7s 164ms/step - loss: 0.3435 - val_loss: 0.3033\n",
            "Epoch 71/200\n",
            "43/43 [==============================] - 8s 193ms/step - loss: 0.3433 - val_loss: 0.3017\n",
            "Epoch 72/200\n",
            "43/43 [==============================] - 7s 152ms/step - loss: 0.3438 - val_loss: 0.3054\n",
            "Epoch 73/200\n",
            "43/43 [==============================] - 8s 194ms/step - loss: 0.3412 - val_loss: 0.2924\n",
            "Epoch 74/200\n",
            "43/43 [==============================] - 6s 150ms/step - loss: 0.3404 - val_loss: 0.2914\n",
            "Epoch 75/200\n",
            "43/43 [==============================] - 8s 194ms/step - loss: 0.3380 - val_loss: 0.2894\n",
            "Epoch 76/200\n",
            "43/43 [==============================] - 7s 164ms/step - loss: 0.3379 - val_loss: 0.2935\n",
            "Epoch 77/200\n",
            "43/43 [==============================] - 8s 191ms/step - loss: 0.3360 - val_loss: 0.2922\n",
            "Epoch 78/200\n",
            "43/43 [==============================] - 6s 149ms/step - loss: 0.3363 - val_loss: 0.2828\n",
            "Epoch 79/200\n",
            "43/43 [==============================] - 8s 191ms/step - loss: 0.3343 - val_loss: 0.2836\n",
            "Epoch 80/200\n",
            "43/43 [==============================] - 6s 150ms/step - loss: 0.3349 - val_loss: 0.2953\n",
            "Epoch 81/200\n",
            "43/43 [==============================] - 8s 191ms/step - loss: 0.3333 - val_loss: 0.2796\n",
            "Epoch 82/200\n",
            "43/43 [==============================] - 6s 150ms/step - loss: 0.3326 - val_loss: 0.2847\n",
            "Epoch 83/200\n",
            "43/43 [==============================] - 8s 192ms/step - loss: 0.3324 - val_loss: 0.2819\n",
            "Epoch 84/200\n",
            "43/43 [==============================] - 6s 150ms/step - loss: 0.3324 - val_loss: 0.2754\n",
            "Epoch 85/200\n",
            "43/43 [==============================] - 8s 193ms/step - loss: 0.3301 - val_loss: 0.2840\n",
            "Epoch 86/200\n",
            "43/43 [==============================] - 7s 152ms/step - loss: 0.3297 - val_loss: 0.2878\n",
            "Epoch 87/200\n",
            "43/43 [==============================] - 8s 193ms/step - loss: 0.3281 - val_loss: 0.2766\n",
            "Epoch 88/200\n",
            "43/43 [==============================] - 6s 149ms/step - loss: 0.3259 - val_loss: 0.2734\n",
            "Epoch 89/200\n",
            "43/43 [==============================] - 8s 194ms/step - loss: 0.3268 - val_loss: 0.2819\n",
            "Epoch 90/200\n",
            "43/43 [==============================] - 6s 149ms/step - loss: 0.3237 - val_loss: 0.2725\n",
            "Epoch 91/200\n",
            "43/43 [==============================] - 9s 207ms/step - loss: 0.3223 - val_loss: 0.2723\n",
            "Epoch 92/200\n",
            "43/43 [==============================] - 6s 151ms/step - loss: 0.3240 - val_loss: 0.2681\n",
            "Epoch 93/200\n",
            "43/43 [==============================] - 8s 192ms/step - loss: 0.3230 - val_loss: 0.2762\n",
            "Epoch 94/200\n",
            "43/43 [==============================] - 6s 150ms/step - loss: 0.3214 - val_loss: 0.2726\n",
            "Epoch 95/200\n",
            "43/43 [==============================] - 8s 196ms/step - loss: 0.3185 - val_loss: 0.2761\n",
            "Epoch 96/200\n",
            "43/43 [==============================] - 6s 149ms/step - loss: 0.3230 - val_loss: 0.2820\n",
            "Epoch 97/200\n",
            "43/43 [==============================] - 8s 195ms/step - loss: 0.3208 - val_loss: 0.2748\n",
            "Epoch 98/200\n",
            "43/43 [==============================] - 6s 150ms/step - loss: 0.3175 - val_loss: 0.2654\n",
            "Epoch 99/200\n",
            "43/43 [==============================] - 9s 210ms/step - loss: 0.3169 - val_loss: 0.2643\n",
            "Epoch 100/200\n",
            "43/43 [==============================] - 7s 158ms/step - loss: 0.3138 - val_loss: 0.2586\n",
            "Epoch 101/200\n",
            "43/43 [==============================] - 8s 198ms/step - loss: 0.3174 - val_loss: 0.2663\n",
            "Epoch 102/200\n",
            "43/43 [==============================] - 7s 153ms/step - loss: 0.3157 - val_loss: 0.2620\n",
            "Epoch 103/200\n",
            "43/43 [==============================] - 9s 211ms/step - loss: 0.3133 - val_loss: 0.2612\n",
            "Epoch 104/200\n",
            "43/43 [==============================] - 6s 149ms/step - loss: 0.3144 - val_loss: 0.2594\n",
            "Epoch 105/200\n",
            "43/43 [==============================] - 8s 196ms/step - loss: 0.3131 - val_loss: 0.2601\n",
            "Epoch 106/200\n",
            "43/43 [==============================] - 6s 151ms/step - loss: 0.3139 - val_loss: 0.2644\n",
            "Epoch 107/200\n",
            "43/43 [==============================] - 8s 195ms/step - loss: 0.3129 - val_loss: 0.2645\n",
            "Epoch 108/200\n",
            "43/43 [==============================] - 7s 153ms/step - loss: 0.3111 - val_loss: 0.2548\n",
            "Epoch 109/200\n",
            "43/43 [==============================] - 9s 198ms/step - loss: 0.3099 - val_loss: 0.2615\n",
            "Epoch 110/200\n",
            "43/43 [==============================] - 6s 150ms/step - loss: 0.3094 - val_loss: 0.2573\n",
            "Epoch 111/200\n",
            "43/43 [==============================] - 8s 193ms/step - loss: 0.3071 - val_loss: 0.2580\n",
            "Epoch 112/200\n",
            "43/43 [==============================] - 7s 169ms/step - loss: 0.3080 - val_loss: 0.2620\n",
            "Epoch 113/200\n",
            "43/43 [==============================] - 8s 182ms/step - loss: 0.3041 - val_loss: 0.2605\n",
            "Epoch 114/200\n",
            "43/43 [==============================] - 7s 161ms/step - loss: 0.3045 - val_loss: 0.2610\n",
            "Epoch 115/200\n",
            "43/43 [==============================] - 8s 186ms/step - loss: 0.3056 - val_loss: 0.2694\n",
            "Epoch 116/200\n",
            "43/43 [==============================] - 7s 166ms/step - loss: 0.3054 - val_loss: 0.2599\n",
            "Epoch 117/200\n",
            "43/43 [==============================] - 9s 198ms/step - loss: 0.3053 - val_loss: 0.2631\n",
            "Epoch 118/200\n",
            "43/43 [==============================] - 8s 181ms/step - loss: 0.3046 - val_loss: 0.2535\n",
            "Epoch 119/200\n",
            "43/43 [==============================] - 7s 168ms/step - loss: 0.3026 - val_loss: 0.2535\n",
            "Epoch 120/200\n",
            "43/43 [==============================] - 8s 183ms/step - loss: 0.3012 - val_loss: 0.2561\n",
            "Epoch 121/200\n",
            "43/43 [==============================] - 7s 162ms/step - loss: 0.3019 - val_loss: 0.2550\n",
            "Epoch 122/200\n",
            "43/43 [==============================] - 8s 186ms/step - loss: 0.3024 - val_loss: 0.2581\n",
            "Epoch 123/200\n",
            "43/43 [==============================] - 7s 173ms/step - loss: 0.2975 - val_loss: 0.2560\n",
            "Epoch 124/200\n",
            "43/43 [==============================] - 8s 199ms/step - loss: 0.2976 - val_loss: 0.2623\n",
            "Epoch 125/200\n",
            "43/43 [==============================] - 7s 153ms/step - loss: 0.2974 - val_loss: 0.2569\n",
            "Epoch 126/200\n",
            "43/43 [==============================] - 8s 196ms/step - loss: 0.2999 - val_loss: 0.2684\n",
            "Epoch 127/200\n",
            "43/43 [==============================] - 7s 166ms/step - loss: 0.2983 - val_loss: 0.2525\n",
            "Epoch 128/200\n",
            "43/43 [==============================] - 8s 193ms/step - loss: 0.2999 - val_loss: 0.2631\n",
            "Epoch 129/200\n",
            "43/43 [==============================] - 7s 153ms/step - loss: 0.2961 - val_loss: 0.2574\n",
            "Epoch 130/200\n",
            "25/43 [================>.............] - ETA: 2s - loss: 0.2963"
          ]
        }
      ],
      "source": [
        "model = get_model(input_dims=(1, 6))\n",
        "model.summary()\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(data_train_X_lstm, y=y_train, epochs=200, batch_size=5000, verbose=1, validation_split=0.3, shuffle=True,\n",
        "          callbacks=[callbacks.EarlyStopping(monitor='val_loss', patience=100, verbose=2, mode='auto')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhxsxiUmpT90"
      },
      "outputs": [],
      "source": [
        "#model = get_model(data_train_X_lstm.shape[1:])\n",
        "#model.summary()\n",
        "#model.compile(optimizer='adam', loss='mse')\n",
        "#model.fit(data_train_X_lstm, y=y_train, epochs=200, batch_size=5000, verbose=1, validation_split=0.3, shuffle=True,\n",
        "          #callbacks=[callbacks.EarlyStopping(monitor='val_loss', patience=100, verbose=2, mode='auto')])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w74GHuObpXbW"
      },
      "outputs": [],
      "source": [
        "y_pred_train = model.predict(data_train_X_lstm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzcYnJDtpeqh"
      },
      "outputs": [],
      "source": [
        "y_pred_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmcPWrWQpgxG"
      },
      "outputs": [],
      "source": [
        "train_Predict_full_range = scaler_Y.inverse_transform(y_pred_train)\n",
        "data_train_Y_full_range = scaler_Y.inverse_transform(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Metrics"
      ],
      "metadata": {
        "id": "S0QsxDXvzkQc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-SGzynkpjNf"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
        "\n",
        "print('RMSE:', np.sqrt(mean_squared_error(y_train, train_Predict_full_range)))\n",
        "print('RMSE Percentage:',rmspe(data_train_Y_full_range, train_Predict_full_range))\n",
        "print('RMSE Percentage-1:',rmspe_1(data_train_Y_full_range, train_Predict_full_range))\n",
        "print('Mean Absolute Error:', mean_absolute_error(data_train_Y_full_range, train_Predict_full_range))\n",
        "print('Mean Absolute Percentage Error:', mean_absolute_percentage_error(data_train_Y_full_range, train_Predict_full_range))\n",
        "print('R^2 Score:', r2_score(data_train_Y_full_range, train_Predict_full_range))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test = model.predict(data_test_X_lstm)"
      ],
      "metadata": {
        "id": "HTQUsB9dvLVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape, y_pred_test.shape"
      ],
      "metadata": {
        "id": "QZkBxu-9vbFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_Predict_full_range = scaler_Y.inverse_transform(y_pred_test)\n",
        "data_test_Y_full_range = scaler_Y.inverse_transform(y_test)"
      ],
      "metadata": {
        "id": "hhmmf91avfQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_absolute_percentage_error, mean_squared_error\n",
        "\n",
        "print('RMSE:',np.sqrt(mean_squared_error(data_test_Y_full_range, test_Predict_full_range)))\n",
        "print('RMSE Percentage:',rmspe(data_test_Y_full_range, test_Predict_full_range))\n",
        "print('RMSE Percentage-1:',rmspe_1(data_test_Y_full_range, test_Predict_full_range))\n",
        "print('Mean Absolute Error:', mean_absolute_error(data_test_Y_full_range, test_Predict_full_range))\n",
        "print('Mean Absolute Percentage Error:', mean_absolute_percentage_error(data_test_Y_full_range, test_Predict_full_range))\n",
        "print('R^2 Score:', r2_score(data_test_Y_full_range, test_Predict_full_range))"
      ],
      "metadata": {
        "id": "wsty7SCpvj9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Katie's Updated Visualiztion Code\n",
        "\n"
      ],
      "metadata": {
        "id": "SGia02O6z5Wv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vb4gGk6WcBHw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBrfYIKVRxzL"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_pred_1201 = model.predict(X_1201_data_lstm)\n",
        "pred1201_normScale = scaler_Y.inverse_transform(y_pred_1201.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7l1qS8sfR0-K"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_Predict_1201_full_flatten=pred1201_normScale.flatten()\n",
        "prediction_on_1201_2D=y_Predict_1201_full_flatten.reshape(1201,1201)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5oSiZbUR3jn"
      },
      "outputs": [],
      "source": [
        "d1201Comparison = pd.DataFrame(prediction_on_1201_2D)\n",
        "\n",
        "#transpose the datasets to face the correct NSEW directions.\n",
        "data_set1 = np.transpose(d1201Comparison)\n",
        "data_set1 = np.flipud(data_set1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-052ZQmeR7k8"
      },
      "outputs": [],
      "source": [
        "x = \"DenseLSTM\"\n",
        "y = \"K_Nearest_Neighbor\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uomfsIcUSrwW"
      },
      "outputs": [],
      "source": [
        "#if interpolatedDataYoureRunning == \"NN\":\n",
        " # print(\"I told you not to use that name. It's not technically correct. Please go back and correct that.\")\n",
        "#else:\n",
        "figRunName = f\"Model {x} with {y} Dataset\"\n",
        "min_value = -626.96027\n",
        "max_value = 778.96765\n",
        "\n",
        "# Create a figure and subplots\n",
        "fig, axs = plt.subplots(1, 1, figsize=(8, 8))\n",
        "\n",
        "# Assuming data_set1 is defined and contains your data\n",
        "# Plot the first data set with shared color scale\n",
        "im1 = axs.imshow(data_set1, vmin=min_value, vmax=max_value)\n",
        "axs.set_title(f'{figRunName}')\n",
        "axs.set_yticklabels(reversed(axs.get_yticklabels()))  # Reverse the y-axis tick labels\n",
        "axs.set_xlabel(\"X Coordinates\")\n",
        "axs.set_ylabel(\"Y Coordinates\")\n",
        "\n",
        "# Define the colormap\n",
        "colors = [\n",
        "      (0.0, 0.0, 0.0),    # Black\n",
        "      (0.0, 0.0, 0.3),    # Darker blue\n",
        "      (0.0, 0.0, 0.5),    # Dark blue\n",
        "      (0.0, 0.0, 0.7),    # Blue\n",
        "      (0.0, 0.0, 1.0),    # Blue\n",
        "      (0.0, 0.4, 0.8),    # Lighter blue\n",
        "      (0.0, 0.6, 0.2),    # Dark green\n",
        "      (0.0, 0.7, 0.3),    # Green\n",
        "      (0.2, 0.8, 0.4),    # Light green\n",
        "      (1.0, 0.8, 0.0),    # Orange\n",
        "      (1.0, 0.0, 0.0),    # Red\n",
        "  ]\n",
        "mapColor = LinearSegmentedColormap.from_list('WaterTreesMountains', colors)\n",
        "# Add colorbar to the plot\n",
        "fig.colorbar(im1, label=\"Target Height (meters)\", ax=axs, location='bottom')\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rfgGT9CUB1-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.subplots(figsize=(15, 5))\n",
        "\n",
        "plt.plot(data_train_Y_full_range, color='red', label=\"Ground Truth\") # Y_test_given,y_pred_test\n",
        "plt.plot(train_Predict_full_range, color='blue', label=\"Prediction\")\n",
        "plt.ylabel(\"Ice Bed Height\")\n",
        "plt.xlabel(\"Data Elements\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIpIyWfDaqNQ"
      },
      "outputs": [],
      "source": [
        "endTime = time.time()\n",
        "print(f\"Total Time Taken: {endTime - startTime:.03f}ms\")\n",
        "print(\"Modeling COMPLETE\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}