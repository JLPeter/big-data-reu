# -*- coding: utf-8 -*-
"""krigingResidualsPyKrige.ipynb
"""

#!pip install pykrige

import pykrige

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error
import h5py
import xarray as xr
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import GradientBoostingRegressor
from sklearn import tree
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import accuracy_score
from sklearn.metrics import roc_auc_score
from pykrige import variogram_models, UniversalKriging, OrdinaryKriging



"""# Import data"""

cols = ['track_bed_x', 'track_bed_y', 'track_bed_target']

df_merged = pd.read_csv('training_test_combined_vmag_ky_230710.csv')[cols]
df_1201 = pd.read_csv('df_1201.csv')
#d_1201=pd.read_csv('df_1201.csv')
df_merged

"""# Data Preprocessing"""

# Remove duplicates by setting to mean

df2 = df_merged.groupby(['track_bed_x', 'track_bed_y']).agg({'track_bed_x':'first', 'track_bed_y':'first', 'track_bed_target':'mean'})
print("num duplicates found: ", len(df_merged) - len(df2))
df_merged = df2.reset_index(drop=True)
df_merged

#df_1201=df_1201.drop(['Unnamed: 0','surf_vx', 'surf_vy', 'surf_elv', 'surf_dhdt', 'surf_SMB'],axis=1)
#df_1201

"""# Define functions"""

def visualizePointsInBox(allTrackX, allTrackY, xCoordMin, xCoordMax, yCoordMin, yCoordMax):
  fig, ax = plt.subplots()
  #ax.scatter(allSurfX, allSurfY, label='Surface points', s=0.2)
  ax.scatter(allTrackX, allTrackY, label='Track bed points', s=0.2)
  # Plot the batches
  # Vertical lines
  ax.axvline(x=xCoordMin, color="black")
  ax.axvline(x=xCoordMax, color="black")
  ax.axhline(yCoordMin, color="black")
  ax.axhline(yCoordMax, color="black")

  ax.set_xlabel('X')
  ax.set_ylabel('Y')
  ax.set_title('Surface data vs track data: batches visualized')
  #ax.legend(loc = "lower right")

  plt.show()

"""# Execute kriging"""

# Validate settings of point grabbing method

# For each point in 1201x1201 dataset
# Grab the track bed data points that are within within box

'''x_bounds_meters = self.Batches_M[batch_i][batch_j]['xBounds']
y_bounds_meters = self.Batches_M[batch_i][batch_j]['yBounds']
x_selected_ind = np.where((x >= x_bounds_meters['min']) & (x <= x_bounds_meters['max']) )[0] # x selected ind
y_selected_ind = np.where((y >= y_bounds_meters['min']) & (y <= y_bounds_meters['max']) )[0]
indicesXY = list(set(x_selected_ind).intersection(y_selected_ind))

xValsCBatch = np.array([x[ind] for ind in indicesXY])
yValsCBatch = np.array([y[ind] for ind in indicesXY])

batchedXVals[batch_i, batch_j] = xValsCBatch
batchedYVals[batch_i, batch_j] = yValsCBatch'''

trackDat = np.array(df_merged)
trackDat.shape
trackDat_x = trackDat[:, 0]
trackDat_y = trackDat[:, 1]

# Box settings
SQUAREBOXWIDTH = 50 # m
EXPANDSTEP = 10 # m
SHRINKSTEP = EXPANDSTEP

MAX_NUM_PTS = 800
MIN_NUM_PTS = 40
METHOD = 'spherical'

# For each point in tracking point dataset
  # Grab the track bed data points that are within  within box (except for that that point)
  # Print size of points grabbed in order to ensure it is reasonable
  # train kriging based on that dataset

boxWidth = SQUAREBOXWIDTH
out = np.empty( (0, 5) ) # (track_bed_x, track_bed_y, target_prediction, target_actual, residual)


for index, row in df_merged.iterrows():
  print("Pixel " + str(index + 1) + " out of " + str(df_merged.shape[0]) )
  # Hold the prediction and ground truth for track_bed_target at the current pixel
  predictionThisRow = None
  groundTruthThisRow = row['track_bed_target']

  trackRowsToTrainOn = None

  print("Trying to find a good box size...")
  xMin, xMax, yMin, yMax = (None, None, None, None)
  expandStep = EXPANDSTEP
  shrinkStep = SHRINKSTEP
  previousProblem = 0 # 1 = too big; -1 = too small
  while True:

    xMin, xMax = (row['track_bed_x'] - boxWidth, row['track_bed_x'] + boxWidth)
    yMin, yMax = (row['track_bed_y'] - boxWidth, row['track_bed_y'] + boxWidth)

    x_selected_ind = np.where((trackDat_x >= xMin) & (trackDat_x <= xMax) )[0]
    y_selected_ind = np.where((trackDat_y >= yMin) & (trackDat_y <= yMax) )[0]
    #visualizePointsInBox(trackDat_x, trackDat_y, xMin, xMax, yMin, yMax)

    # Select indices that are in selected x and y range (inside the rectangle) to init object on
    indicesXY = list(set(x_selected_ind).intersection(y_selected_ind))
    trackRowsToTrainOn = np.array([trackDat[ind] for ind in indicesXY])

    # If none were selected, perform same code as if some but too few were selected
    if (len(trackRowsToTrainOn) < MIN_NUM_PTS):

      # Prevent overshooting by reducing step size
      if (previousProblem == 1): # Was too big last time
        expandStep /= 2
      else:
        pass#expandStep *= 1.5

      boxWidth += expandStep
      previousProblem = -1
      continue

    # Remove the row corresponding to the center point
    mask = np.logical_and(trackRowsToTrainOn[:, 0] == row['track_bed_x'], trackRowsToTrainOn[:, 1] == row['track_bed_y'])
    trackRowsToTrainOn = trackRowsToTrainOn[~mask] # Grab track rows that exclude it
    #print(trackRowsToTrainOn)

    # Print number of points
    numPts = len(trackRowsToTrainOn)
    #print(numPts)

    # Perform iterative resizing of box to ensure correct length
    if (numPts < MIN_NUM_PTS):

      # Prevent overshooting by reducing step size
      if (previousProblem == 1): # Was too big last time
        expandStep /= 2
      else:
        pass#expandStep *= 1.5

      boxWidth += expandStep
      previousProblem = -1
    elif (numPts > MAX_NUM_PTS):

      # Prevent overshooting by reducing step size
      if (previousProblem == -1): # Was too small last time
        shrinkStep /= 2
      else:
        pass#shrinkStep *= 1.5

      boxWidth -= shrinkStep
      previousProblem = 1
    else:
      break # We have chosen an appropriate number of trackRowsToTrainOn
  print("Appropriate box selected; points extracted to trackRowsToTrainOn.")

  # Fit the variogram model
  print("Fit variogram model...")
  kriging = UniversalKriging(trackRowsToTrainOn[:, 0], trackRowsToTrainOn[:, 1], trackRowsToTrainOn[:, 2], variogram_model=METHOD, nlags=len(trackRowsToTrainOn[:, 1])) # this tries to fit the linear model to it
  print("Making prediction for current pixel...")
  prediction, predictionVariance = kriging.execute("points", row['track_bed_x'], row['track_bed_y'])
  predictionThisRow = prediction[0]

  print("Calculating residual of prediction...")
  residualThisRow = predictionThisRow - groundTruthThisRow

  print("Saving results for this data point to dataframe...")
  new_arr = np.array([  [row['track_bed_x'], row['track_bed_y'], predictionThisRow, groundTruthThisRow, residualThisRow ] ])
  out = np.vstack( (out, new_arr))
  print("prediction", predictionThisRow, "residual", residualThisRow)
  print("Results saved.")
  #if index == 29:
    #break
  print()

print("Finished applying kriging to all tracking pixels.")

from datetime import datetime

df_krigout = pd.DataFrame(columns = ["track_bed_x", "track_bed_y", "target_prediction", "target_true", "residual"], data=out)
df_krigout.to_csv("Kriging.csv")

print(METHOD)

print(SQUAREBOXWIDTH)
print()
print(MIN_NUM_PTS)
print(MAX_NUM_PTS)

print()
print(EXPANDSTEP)
print(SHRINKSTEP)

print(df_krigout['residual'].abs())
print()
print(df_krigout['residual'].abs().mean())

# Predict residual
