# **Exploring New Symbolic Regression Models**

### **Introduction**
Machine learning models can be improved by incorporating prior knowledge into the training process. Adding knowledge-based loss terms to a model's loss function penalizes models that stray away from meeting the criteria that the response variable should follow. We added such loss functions into the source code of GP-GOMEA, with the goal of generating more accurate symbolic
expressions.

Loss functions implemented for the symbolic regression model:

1.   Z-R relation
2.   Silhouette score
3.   Deviations from rainfall group

Like for `Benchmarking Existing Symbolic Regression Models`, the data is split into 75% training and 25% testing with the `random_state` parameter changed each trial so that the training and testing sets differ using scikit-learn's `train_test_split()`.

### **Setup and Installation**
[GP-GOMEA](https://github.com/marcovirgolin/GP-GOMEA) is required to run these benchmarks. Install their package according to their documentation.



#### **How to include the knowledge-based loss terms in the training process of GP-GOMEA:**

1) Copy the contents of `sk_new.py` from the `gpg Source code` folder.

2) Find the location of the `gpg` package on your local machine.

3) Open the`sk.py` file **within the gpg source code**.

4) Replace everything in the `sk.py` file within the gpg source code with the contents of `sk_new.py`.

5) Repeat steps 1) through 4) but with `finetuning_new.py` and `finetuning.py`.

### **Quickstart for training the gpg model**
To run `train_gpg_models.py`, First activate the gpg conda environment. Next, modify the following code to match the dataset's path on your local machine:
```
  # import datasets
  df = pd.read_csv("/your_dataset_path_here")
```
 The script accepts the following command line arguments:

| Argument      | Description | Options
| ----------- | ----------- |----------
| --loss      | string: specifies type of loss function       | regular, Z-R, clusters, binned-rainfall
| --weight   | float: the weight parameter for the loss function        | any float
| --clustername | string: the column name for the cluster labels | any string

Here is an example running the script:

```
python train_gpg_models.py --loss clusters --weight 2.3 --clustername cluster_kmeans_rho_zdr
```

##### **Note**: To use the silhouette score loss function, the data needs to have a column that seperates the data into **3** groups (such as with a clustering algorithm like k-means clustering). This column will contain a label for the group that each observation is in.

After running the script, an output CSV is produced containing various metrics such as `train R^2`, `test R^2`, `train_NRMSE`, `test_NRMSE`, `simplicity`, and the `equation` for each iteration.

### **Other files**
`zr_relation.py` uses the Z-R (Relectivity-Rainfall) relationship (Z=aR^b) to predict rainfall rates using various values of a and b. One set of values is generated by scipy's `optimize()` function. It reports the R^2 and NRMSE scores associated with these predictions. This will allow for the optimal values of a and b for the Z-R relationship to be found.

`plot_results.py` allows you to input an equation generated by a symbolic regression model and plot the actual vs. predicted rainfall rates.