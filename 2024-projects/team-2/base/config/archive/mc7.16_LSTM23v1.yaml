run_id: 'mc7.16_LSTM23v1'
pred_ckpt: '/nfs/rs/cybertrn/reu2024/team2/base/logs/tb_logs/mc7.16_LSTM23v1/lightning_logs/version_3/checkpoints/epoch=2999-step=243000.ckpt'
resume_ckpt: ''
mdl_key: 'LSTM23'  # added for pred

data:
  train_data_path: '/nfs/rs/cybertrn/reu2024/team2/base/pp2/data/barajas/train/'  # must include '/' at end
  test_data_path: '/nfs/rs/cybertrn/reu2024/team2/base/pp2/data/barajas/test/'  # changed this jul 22
  batch_size: 4096
  val_split: 0.1

fit:
  max_epochs: 3000
  n_nodes: 1
  n_devices: 1
  patience: 300

model:
  # hidden_units: (0,0)
  # lr: 0.0
  # # 2023 LSTM
  # deleted these cuz new code, was actually compiling but that's sketchy...
  # indim: 15
  # outdim: 13
  # num_layers: 16
  # neurons: 256
  # momentum: 0.1

  # running tests on jul 22, so had to add these
  # 2023 LSTM
  indim: 15
  outdim: 13
  num_layers: 16
  neurons: 256
  lr: 0.001
  lr_step: 400
  lr_gam: 0.95
  dropout: 0.2
  activation: 'relu'
  optimizer: 'adam'
  