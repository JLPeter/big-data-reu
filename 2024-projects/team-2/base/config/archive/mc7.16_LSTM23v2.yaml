# shouldn't be deleting any of these
run_id: 'mc7.16_LSTM23v2'
pred_ckpt: '/nfs/rs/cybertrn/reu2024/team2/base/logs/tb_logs/mc7.16_LSTM23v2/lightning_logs/version_1/checkpoints/epoch=4999-step=155000.ckpt'  # only use if doing inference
mdl_key: 'LSTM23'

data:  # shouldn't be deleting any of these
  train_data_path: '/nfs/rs/cybertrn/reu2024/team2/base/pp2/data/barajas24/train/'  # must include '/' at end
  test_data_path: '/nfs/rs/cybertrn/reu2024/team2/base/pp2/data/barajas24/test/'  # also predict path atm
  batch_size: 2048
  val_split: 0.1

fit:  # shouldn't be deleting any of these
  max_epochs: 5000
  n_nodes: 3
  n_devices: 8
  patience: 500  # make arbitrarily large to turn off early stopping

model:  # should match the model you are using
  indim: 15
  outdim: 13
  num_layers: 16
  neurons: 256
  momentum: 0.1
  