# shouldn't be deleting any of these
run_id: 'jh7.24_impr_lstm_ep_mship'
pred_ckpt: '/nfs/rs/cybertrn/reu2024/team2/base/logs/tb_logs/jh7.24_impr_lstm_ep_mship/lightning_logs/version_1/checkpoints/epoch=2999-step=507000.ckpt'  # only change if doing inference
resume_ckpt: ''  # leave as '' if not resuming
mdl_key: 'impr_lstm23'

data:  # shouldn't be deleting any of these
  train_data_path: '/nfs/rs/cybertrn/reu2024/team2/base/pp2/data/mship_v2/train/'  # must include '/' at end
  test_data_path: '/nfs/rs/cybertrn/reu2024/team2/base/pp2/data/mship_v2/og-test/'
  batch_size: 4096
  val_split: .2

fit:  # shouldn't be deleting any of these
  max_epochs: 4096 
  n_nodes: 1
  n_devices: 4
  patience: 5000  # make arbitrarily large to turn off early stopping

model:  # should match the model you are using
  indim: 15
  outdim: 13
  num_layers: 16
  neurons: [256,256,256,256]
  lr: 0.001
  lr_step: 400
  lr_gam: 0.95
  dropout: 0.15
  activation: 'relu'
  penalty: 0.0001
  optimizer: 'adam'
