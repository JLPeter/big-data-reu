# same as v1 but different loss, a lot more gpus, and 2 for the penalty, and dropout, and learning rate
run_id: 'mc7.25_imFCNv2'
pred_ckpt: '/nfs/rs/cybertrn/reu2024/team2/base/logs/tb_logs/mc7.25_imFCNv2/lightning_logs/version_0/checkpoints/epoch=6999-step=749000.ckpt' 
resume_ckpt: ''
mdl_key: 'impr_fcn'

data:  
  train_data_path: '/nfs/rs/cybertrn/reu2024/team2/base/pp2/data/barajas_test/train/' 
  test_data_path: '/nfs/rs/cybertrn/reu2024/team2/base/pp2/data/barajas_test/test/'
  batch_size: 2048
  val_split: 0.2

fit:  
  max_epochs: 8000
  n_nodes: 2
  n_devices: 3
  patience:  3000 
  ckpt_freq: 100

model:  
  input_size: 15
  num_classes: 13
  hidden_layers: [2048,1024,678,576,512,256,256,256,256,256,256,256,256,64,32,16]
  activation: 'relu'
  lr: 0.005
  lr_step: 500
  lr_gam: 0.95
  penalty: 2
  dropout: 0.3
  #l2: 0.001


